{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer # this is the transformer.py file\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', '5', 'ద', 'U', 'థ', 'k', 'X', 'ౌ', 'ఔ', 'ఉ', 'మ', 'త', '\"', 'H', 'ఫ', 'M', '?', '%', 'ీ', 'E', 'ఊ', 'V', ' ', 'క', '3', 'L', 'ఋ', 'ఠ', 'ొ', 'ణ', 'O', 'i', 'v', 'b', 'm', 'S', 'ా', 'ె', 'c', 'ఞ', 'C', 'జ', 'G', 'ఆ', '9', 'j', 'ఈ', 'N', 'd', 'R', 'F', 'B', 'T', 'W', '+', 'h', 'D', 'P', 'ల', ';', '్', 'I', 'y', '2', '/', 'ఛ', 'ై', 'ఒ', 'ఇ', 'ృ', '₂', 'ర', '\\n', '.', 'x', '-', 'ట', 'w', 'K', '8', 'r', 'n', 'ధ', 'అ', 'g', '4', 'ళ', 'ఏ', 'హ', 'భ', 'ూ', 'బ', \"'\", 'చ', 'ే', 'ౖ', '1', 'u', 'o', '€', 'వ', 'య', 'ఘ', 'ఙ', 'Y', 'ం', 'ి', 'A', 'ో', 'f', 'శ', 'ు', 'ప', ',', '0', 'డ', ':', '6', 't', '$', 'ఎ', 'p', 'గ', 'ష', 'e', '&', 'స', '7', 'J', '\\u200c', 'ఐ', 'ఖ', 'ః', 'a', '!', 's', 'ఓ', 'న']\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "english_sentences=[]\n",
    "telugu_sentences=[]\n",
    "m=0\n",
    "telugu_vocab=set()\n",
    "english_telugu_file='english_telugu_data.txt'\n",
    "with open(english_telugu_file,'r') as f:\n",
    "    sentences = f.readlines()\n",
    "for each in sentences:\n",
    "    s=each.split('++++$++++')\n",
    "    english_sentences.append(s[0])\n",
    "    telugu_sentences.append(s[1])\n",
    "    \n",
    "for each in telugu_sentences:\n",
    "    \n",
    "    for j in each:\n",
    "        telugu_vocab.add(j)\n",
    "\n",
    "print(list(telugu_vocab))\n",
    "print(len(telugu_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who taught Tom how to speak French?\n",
      "టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(english_sentences[1])\n",
    "print(telugu_sentences[1])\n",
    "kannada_sentences=telugu_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PADDING>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "kannada_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
    "                     '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ఁ', \n",
    "                     'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ',\n",
    "                     'క', 'ఖ', 'గ', 'ఘ', 'ఙ', \n",
    "                     'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', \n",
    "                     'ట', 'ఠ', 'డ', 'ఢ', 'ణ', \n",
    "                     'త', 'థ', 'ద', 'ధ', 'న', \n",
    "                     'ప', 'ఫ', 'బ', 'భ', 'మ', \n",
    "                     'య', 'ర', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', \n",
    "                     'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', '౎', \n",
    "                     'ౠ', 'ౡ', '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "kannada_vocabulary=[START_TOKEN,'l', '5', 'ద', 'U', 'థ', 'k', 'X', 'ౌ', 'ఔ', 'ఉ', 'మ', 'త', '\"', 'H', 'ఫ', 'M', '?', '%', 'ీ', 'E', 'ఊ', \n",
    "                    'V', ' ', 'క', '3', 'L', 'ఋ', 'ఠ', 'ొ', 'ణ', 'O', 'i', 'v', 'b', 'm', 'S', 'ా', 'ె', 'c', 'ఞ', 'C', 'జ', 'G', 'ఆ',\n",
    "                      '9', 'j', 'ఈ', 'N', 'd', 'R', 'F', 'B', 'T', 'W', '+', 'h', 'D', 'P', 'ల', ';', '్', 'I', 'y', '2', '/', 'ఛ', 'ై', 'ఒ',\n",
    "                        'ఇ', 'ృ', '₂', 'ర', '\\n', '.', 'x', '-', 'ట', 'w', 'K', '8', 'r', 'n', 'ధ', 'అ', 'g', '4', 'ళ', 'ఏ', 'హ', 'భ', 'ూ',\n",
    "                          'బ', \"'\", 'చ', 'ే', 'ౖ', '1', 'u', 'o', '€', 'వ', 'య', 'ఘ', 'ఙ', 'Y', 'ం', 'ి', 'A', 'ో', 'f', 'శ', 'ు', 'ప', ',', \n",
    "                          '0', 'డ', ':', '6', 't', '$', 'ఎ', 'p', 'గ', 'ష', 'e', '&', 'స', '7', 'J', '\\u200c', 'ఐ', 'ఖ', 'ః', 'a', '!', 's', \n",
    "                          'ఓ', 'న', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@',\n",
    "                        '[', '\\\\', ']', '^', '_', '`', \n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                        'y', 'z', \n",
    "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
    "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SENTENCES = 155798\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
    "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
    "kannada_sentences = [sentence.rstrip('\\n') for sentence in kannada_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['his legs are long.',\n",
       " 'who taught tom how to speak french?',\n",
       " 'i swim in the sea every day.',\n",
       " 'tom popped into the supermarket on his way home to buy some milk.',\n",
       " 'smoke filled the room.',\n",
       " 'tom and mary understood each other.',\n",
       " 'many men want to be thin, too.',\n",
       " 'we need three cups.',\n",
       " 'i warned tom not to come here.',\n",
       " 'you two may leave.']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['అతని కాళ్ళు పొడవుగా ఉన్నాయి.',\n",
       " 'టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?',\n",
       " 'నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.',\n",
       " 'టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడు సూపర్ మార్కెట్లోకి ప్రవేశించాడు.',\n",
       " 'పొగ గదిని నింపింది.',\n",
       " 'టామ్ మరియు మేరీ ఒకరినొకరు అర్థం చేసుకున్నారు.',\n",
       " 'చాలా మంది పురుషులు కూడా సన్నగా ఉండాలని కోరుకుంటారు.',\n",
       " 'మాకు మూడు కప్పులు అవసరం.',\n",
       " 'టామ్\\u200cను ఇక్కడికి రానివ్వమని హెచ్చరించాను.',\n",
       " 'మీరిద్దరూ వెళ్ళవచ్చు.']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length Kannada: 60.0\n",
      "97th percentile length English: 56.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in kannada_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 155798\n",
      "Number of valid sentences: 155792\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(kannada_sentences)):\n",
    "    kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(kannada_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['అతని కాళ్ళు పొడవుగా ఉన్నాయి.',\n",
       " 'టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?',\n",
       " 'నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 600\n",
    "kn_vocab_size = len(kannada_vocabulary)\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          ffn_hidden,\n",
    "                          num_heads, \n",
    "                          drop_prob, \n",
    "                          num_layers, \n",
    "                          max_sequence_length,\n",
    "                          kn_vocab_size,\n",
    "                          english_to_index,\n",
    "                          kannada_to_index,\n",
    "                          START_TOKEN, \n",
    "                          END_TOKEN, \n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(71, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(141, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm3): LayerNormalization()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=141, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, english_sentences, kannada_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.kannada_sentences = kannada_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.kannada_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155792"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TextDataset(english_sentences, kannada_sentences)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('who taught tom how to speak french?',\n",
       " 'టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('his legs are long.', 'who taught tom how to speak french?', 'i swim in the sea every day.', 'tom popped into the supermarket on his way home to buy some milk.', 'smoke filled the room.', 'tom and mary understood each other.', 'many men want to be thin, too.', 'we need three cups.', 'i warned tom not to come here.', 'you two may leave.', 'he feels very happy.', \"tom wasn't smiling when he entered the room.\", 'what can it be?', 'is your car black?', 'i have to take my medicine every six hours.', 'tom can fix the heater.', \"it's almost dawn and nothing's happened yet.\", 'is tom smarter than you?', \"don't take their word for it.\", \"the air conditioner doesn't work.\", \"i don't think i've ever been this happy.\", \"we don't know where they are now.\", \"maybe they will come and maybe they won't.\", \"i'll see what else needs to be done.\", 'if the weather is nice tomorrow, we will have a picnic.', 'how many times did you visit your grandparents last year?', \"i'm not as brave as tom.\", 'in england, in the summer, the sun rises at about 4 a.m.', 'please tell us what happened.', \"the police can't stop this.\"), ('అతని కాళ్ళు పొడవుగా ఉన్నాయి.', 'టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?', 'నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.', 'టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడు సూపర్ మార్కెట్లోకి ప్రవేశించాడు.', 'పొగ గదిని నింపింది.', 'టామ్ మరియు మేరీ ఒకరినొకరు అర్థం చేసుకున్నారు.', 'చాలా మంది పురుషులు కూడా సన్నగా ఉండాలని కోరుకుంటారు.', 'మాకు మూడు కప్పులు అవసరం.', 'టామ్\\u200cను ఇక్కడికి రానివ్వమని హెచ్చరించాను.', 'మీరిద్దరూ వెళ్ళవచ్చు.', 'అతను చాలా సంతోషంగా ఉన్నాడు.', 'గదిలోకి ప్రవేశించినప్పుడు టామ్ నవ్వలేదు.', 'అది ఏమిటి?', 'మీ కారు నల్లగా ఉందా?', 'ప్రతి ఆరు గంటలకు నా medicine షధం తీసుకోవాలి.', 'టామ్ హీటర్ను పరిష్కరించగలడు.', 'ఇది దాదాపు తెల్లవారుజాము మరియు ఇంకా ఏమీ జరగలేదు.', 'టామ్ మీ కంటే తెలివిగా ఉన్నారా?', 'దాని కోసం వారి మాటను తీసుకోకండి.', 'ఎయిర్ కండీషనర్ పనిచేయదు.', 'నేను ఇంత సంతోషంగా ఉన్నానని నేను అనుకోను.', 'వారు ఇప్పుడు ఎక్కడ ఉన్నారో మాకు తెలియదు.', 'బహుశా వారు వస్తారు మరియు వారు రాకపోవచ్చు.', 'ఇంకా ఏమి చేయాలో నేను చూస్తాను.', 'రేపు వాతావరణం బాగుంటే, మాకు పిక్నిక్ ఉంటుంది.', 'గత సంవత్సరం మీరు మీ తాతామామలను ఎన్నిసార్లు సందర్శించారు?', 'నేను టామ్ లాగా ధైర్యంగా లేను.', 'ఇంగ్లాండ్\\u200cలో, వేసవిలో, ఉదయం 4 గంటలకు సూర్యుడు ఉదయిస్తాడు.', 'దయచేసి ఏమి జరిగిందో మాకు చెప్పండి.', 'పోలీసులు దీనిని ఆపలేరు.')]\n",
      "[('she knows nothing about your family.', 'tom said that he needed a rest.', \"we're going to be here all afternoon.\", 'it may rain tomorrow.', \"don't ruin our fun.\", 'i demand that he be punished.', \"nobody's going anywhere.\", 'that man is dead.', \"tom doesn't want this.\", 'tom put on his black suit and white tie.', 'you always said you wanted to become a teacher.', 'tom said that he felt cold.', 'i slept late and i missed the first train.', \"we're a little early.\", 'tom buys me things that i want.', 'does that window open?', 'how many english words do you know?', \"you're welcome to any book in my library.\", 'i wish i were rich.', 'are you going or not?', \"we're not accusing you of anything.\", \"i couldn't eat fish when i was a child.\", 'tom wants to say hello.', \"are you saying this doesn't matter?\", \"i've heard that you shouldn't eat red meat more than once a day.\", \"i don't know why i even bother anymore.\", 'she was in the hospital for six weeks because she was sick.', 'you and i should stick together.', 'about how much will it cost?', 'tom let me stay with mary.'), ('మీ కుటుంబం గురించి ఆమెకు ఏమీ తెలియదు.', 'తనకు విశ్రాంతి అవసరమని టామ్ చెప్పాడు.', 'మేము మధ్యాహ్నం అంతా ఇక్కడే ఉండబోతున్నాం.', 'రేపు వర్షం పడవచ్చు.', 'మా సరదాని నాశనం చేయవద్దు.', 'అతన్ని శిక్షించాలని నేను కోరుతున్నాను.', 'ఎవరూ ఎక్కడికి వెళ్ళడం లేదు.', 'ఆ మనిషి చనిపోయాడు.', 'టామ్\\u200cకు ఇది అక్కరలేదు.', 'టామ్ తన బ్లాక్ సూట్ మరియు వైట్ టై ధరించాడు.', 'మీరు గురువు కావాలని మీరు ఎప్పుడూ చెప్పారు.', 'టామ్ తనకు చలిగా అనిపించింది.', 'నేను ఆలస్యంగా నిద్రపోయాను మరియు నేను మొదటి రైలును కోల్పోయాను.', 'మేము కొంచెం ముందుగానే ఉన్నాము.', 'టామ్ నాకు కావలసిన వస్తువులను కొంటాడు.', 'ఆ విండో తెరుచుకుంటుందా?', 'మీకు ఎన్ని ఆంగ్ల పదాలు తెలుసు?', 'నా లైబ్రరీలోని ఏదైనా పుస్తకానికి మీకు స్వాగతం.', 'నేను ధనవంతుడిని అని కోరుకుంటున్నాను.', 'మీరు వెళ్తున్నారా లేదా?', 'మేము మీపై ఏమీ ఆరోపణలు చేయడం లేదు.', 'నేను చిన్నతనంలో చేపలు తినలేను.', 'టామ్ హలో చెప్పాలనుకుంటున్నాడు.', 'ఇది పట్టింపు లేదని మీరు చెబుతున్నారా?', 'మీరు ఎర్ర మాంసం రోజుకు ఒకటి కంటే ఎక్కువసార్లు తినకూడదని విన్నాను.', 'నేను ఇక ఎందుకు బాధపడుతున్నానో నాకు తెలియదు.', 'ఆమె అనారోగ్యంతో ఆరు వారాలపాటు ఆసుపత్రిలో ఉంది.', 'మీరు మరియు నేను కలిసి ఉండాలి.', 'దీని ధర ఎంత?', 'టామ్ నన్ను మేరీతో కలిసి ఉండనివ్వండి.')]\n",
      "[('i know i deserve this.', \"let's talk about your work.\", 'tom cut his sister a piece of cake.', 'is everyone against him?', \"i'll be in the basement.\", 'i want tom to read this.', \"don't make eye contact.\", 'could you tell me where tom is?', \"you're my boss.\", 'never hesitate to tell the truth.', 'tom has got nowhere to go.', 'tom is their leader.', 'the lighting blinded me for a while.', 'could you show me this bag?', 'tom and i are planning on getting married on october 20th.', \"i've been to the supermarket.\", 'he is now almost as tall as his father is.', 'i was unable to control myself any longer.', 'try doing that again.', 'this dish is too spicy.', \"tom told me i shouldn't talk to you.\", 'how many people are on board the ship?', 'was that tom you were just talking to?', \"don't tell my wife that.\", 'tom looked out the window and saw mary.', 'tom is most likely eating now.', 'can you translate this manuscript from french to english?', 'the only spice tom puts on meat is pepper.', 'tom says his left leg hurts.', 'i heard that he left town and moved east.'), ('నేను దీనికి అర్హుడని నాకు తెలుసు.', 'మీ పని గురించి మాట్లాడుకుందాం.', 'టామ్ తన సోదరికి కేక్ ముక్కను కత్తిరించాడు.', 'అందరూ ఆయనకు వ్యతిరేకంగా ఉన్నారా?', 'నేను నేలమాళిగలో ఉంటాను.', 'టామ్ దీన్ని చదవాలని నేను కోరుకుంటున్నాను.', 'కంటికి పరిచయం చేయవద్దు.', 'టామ్ ఎక్కడ ఉన్నారో మీరు నాకు చెప్పగలరా?', 'నువ్వు నా బాస్.', 'నిజం చెప్పడానికి ఎప్పుడూ వెనుకాడరు.', 'టామ్ ఎక్కడికి వెళ్ళలేదు.', 'టామ్ వారి నాయకుడు.', 'లైటింగ్ కాసేపు నన్ను కళ్ళుమూసుకుంది.', 'మీరు ఈ బ్యాగ్ నాకు చూపించగలరా?', 'టామ్ మరియు నేను అక్టోబర్ 20 న వివాహం చేసుకోవాలని యోచిస్తున్నాము.', 'నేను సూపర్ మార్కెట్\\u200cకు వెళ్లాను.', 'అతను ఇప్పుడు తన తండ్రి ఉన్నంత ఎత్తులో ఉన్నాడు.', 'నేను ఇకపై నన్ను నియంత్రించలేకపోయాను.', 'మళ్ళీ అలా ప్రయత్నించండి.', 'ఈ వంటకం చాలా కారంగా ఉంటుంది.', 'నేను మీతో మాట్లాడకూడదని టామ్ చెప్పాడు.', 'ఓడలో ఎంత మంది ఉన్నారు?', 'ఆ టామ్ మీరు ఇప్పుడే మాట్లాడుతున్నారా?', 'నా భార్యకు అలా చెప్పకండి.', 'టామ్ కిటికీలోంచి చూస్తూ మేరీని చూశాడు.', 'టామ్ ఇప్పుడు ఎక్కువగా తినడం.', 'మీరు ఈ మాన్యుస్క్రిప్ట్\\u200cను ఫ్రెంచ్ నుండి ఇంగ్లీషులోకి అనువదించగలరా?', 'టామ్ మాంసం మీద ఉంచే మసాలా మిరియాలు మాత్రమే.', 'తన ఎడమ కాలు బాధిస్తుందని టామ్ చెప్పాడు.', 'అతను పట్టణం వదిలి తూర్పుకు వెళ్ళాడని నేను విన్నాను.')]\n",
      "[('we were kids together.', \"isn't that the golden gate bridge?\", \"there's almost no milk left in the glass.\", 'tom called me this afternoon.', 'tom read mary a bedtime story.', \"there's the bell.\", 'are you good at remembering faces?', 'tom and mary wanted to be together.', \"tom's wicked.\", 'you must try and come to the party.', \"you saw them, didn't you?\", 'the doctor took his pulse.', \"we're thinking about putting our house up for sale.\", 'would you please pour me a cup of coffee?', 'we kept together for safety.', 'tom is eating a cake.', \"odd, isn't it? we should have already arrived.\", \"mary's not pretty, but she isn't ugly, either.\", \"i'm sorry, you have the wrong number.\", 'he is a man of his word.', 'he always took a seat in the front row.', 'the pond has frozen over.', 'i know the boy.', 'he was not about to admit his mistake.', \"i don't think i can do everything by myself.\", \"i suppose you'll be studying all day tomorrow.\", \"mary is tom's daughter-in-law.\", \"i'll go if you will.\", 'tom tried to hide his confusion.', \"you're turning red.\"), ('మేము కలిసి పిల్లలు.', 'అది గోల్డెన్ గేట్ వంతెన కాదా?', 'గాజులో దాదాపు పాలు లేవు.', 'టామ్ ఈ మధ్యాహ్నం నన్ను పిలిచాడు.', 'టామ్ మేరీకి నిద్రవేళ కథ చదివాడు.', 'గంట ఉంది.', 'మీరు ముఖాలను గుర్తుంచుకోవడంలో మంచివా?', 'టామ్ మరియు మేరీ కలిసి ఉండాలని కోరుకున్నారు.', 'టామ్ యొక్క దుష్ట.', 'మీరు తప్పక ప్రయత్నించాలి మరియు పార్టీకి రావాలి.', 'మీరు వాటిని చూశారు, లేదా?', 'డాక్టర్ అతని పల్స్ తీసుకున్నాడు.', 'మేము మా ఇంటిని అమ్మకానికి పెట్టడం గురించి ఆలోచిస్తున్నాము.', 'దయచేసి నాకు ఒక కప్పు కాఫీ పోయాలా?', 'మేము భద్రత కోసం కలిసి ఉంచాము.', 'టామ్ కేక్ తింటున్నాడు.', 'బేసి, కాదా?', 'మేరీ అందంగా లేదు, కానీ ఆమె అగ్లీ కాదు.', 'క్షమించండి, మీకు తప్పు సంఖ్య ఉంది.', 'అతను తన మాటలోని వ్యక్తి.', 'అతను ఎప్పుడూ ముందు వరుసలో ఒక సీటు తీసుకున్నాడు.', 'చెరువు స్తంభింపజేసింది.', 'నాకు అబ్బాయి తెలుసు.', 'అతను తన తప్పును అంగీకరించడం లేదు.', 'నేను ప్రతిదాన్ని స్వయంగా చేయగలనని నేను అనుకోను.', 'మీరు రేపు రోజంతా చదువుతారని అనుకుందాం.', 'మేరీ టామ్ యొక్క అల్లుడు.', 'మీరు కోరుకుంటే నేను వెళ్తాను.', 'టామ్ తన గందరగోళాన్ని దాచడానికి ప్రయత్నించాడు.', 'మీరు ఎరుపు రంగులోకి మారుతున్నారు.')]\n",
      "[('i will accept the work, provided that you help me.', \"tom didn't seem happy to see me.\", 'my watch loses three minutes a week.', \"why can't tom leave?\", 'the poor girl went blind.', 'i found out something interesting today.', 'tom loaded the truck with sand.', \"they don't understand me when i speak german.\", 'tom is the only person who can do that, i think.', 'i know why tom agreed to do that.', 'tom turned down the radio.', 'she was asked not to speak at the meeting.', \"i'm not sure if i'm going to be able to be there on time.\", 'the damage was covered by insurance.', 'there was a bridge across each river.', \"i've got a little problem.\", \"tom can't afford to buy a yacht.\", 'the policeman put handcuffs on tom.', 'i value my privacy.', 'stop protecting me.', 'please accept my apology.', \"i've already spoken to tom about that.\", 'i wonder if tom would really do something like that.', 'tom taught me to play chess.', 'i just got here this morning.', 'tom is between jobs.', 'tom certainly knew about the problem.', 'ok, i think we can begin.', 'my grandfather has gray hair.', 'could you give me a lift home?'), ('మీరు నాకు సహాయం చేస్తే నేను పనిని అంగీకరిస్తాను.', 'టామ్ నన్ను చూడటం సంతోషంగా అనిపించలేదు.', 'నా గడియారం వారానికి మూడు నిమిషాలు కోల్పోతుంది.', 'టామ్ ఎందుకు వెళ్ళలేడు?', 'పేద అమ్మాయి అంధురాలైంది.', 'నేను ఈ రోజు ఆసక్తికరమైన విషయం కనుగొన్నాను.', 'టామ్ ఇసుకతో ట్రక్కును ఎక్కించాడు.', 'నేను జర్మన్ మాట్లాడేటప్పుడు వారు నన్ను అర్థం చేసుకోరు.', 'టామ్ మాత్రమే అలా చేయగలడు, నేను అనుకుంటున్నాను.', 'టామ్ ఎందుకు అలా అంగీకరించాడో నాకు తెలుసు.', 'టామ్ రేడియోను తిరస్కరించాడు.', 'సమావేశంలో మాట్లాడవద్దని ఆమెను కోరారు.', 'నేను సమయానికి అక్కడ ఉండగలనా అని నాకు తెలియదు.', 'నష్టం భీమా పరిధిలోకి వచ్చింది.', 'ప్రతి నదికి ఒక వంతెన ఉండేది.', 'నాకు కొద్దిగా సమస్య వచ్చింది.', 'టామ్ ఒక పడవ కొనడానికి భరించలేడు.', 'పోలీసు టామ్\\u200cపై హస్తకళలు పెట్టాడు.', 'నా గోప్యతకు నేను విలువ ఇస్తున్నాను.', 'నన్ను రక్షించడం ఆపు.', 'దయచేసి నా క్షమాపణను అంగీకరించండి.', 'నేను ఇప్పటికే టామ్\\u200cతో దాని గురించి మాట్లాడాను.', 'టామ్ నిజంగా అలాంటిదే చేస్తాడా అని నేను ఆశ్చర్యపోతున్నాను.', 'టామ్ నాకు చెస్ ఆడటం నేర్పించాడు.', 'నేను ఈ ఉదయం ఇక్కడకు వచ్చాను.', 'టామ్ ఉద్యోగాల మధ్య ఉన్నాడు.', 'టామ్ ఖచ్చితంగా సమస్య గురించి తెలుసు.', 'సరే, మనం ప్రారంభించవచ్చని అనుకుంటున్నాను.', 'నా తాతకు బూడిద జుట్టు ఉంది.', 'మీరు నాకు లిఫ్ట్ హోమ్ ఇవ్వగలరా?')]\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)\n",
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=kannada_to_index[PADDING_TOKEN],\n",
    "                                reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, kn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : 5.60818338394165\n",
      "English: his legs are long.\n",
      "Kannada Translation: అతని కాళ్ళు పొడవుగా ఉన్నాయి.\n",
      "Kannada Prediction: XపఘDDదXnXnnXఆnఆnnnnnnఆఆఆnnWWnశm%%%%WbుW<PADDING>bbbXWbఙఙవవbbbnbWWWWWnుుుుుఙ-WW-అవW333వవWWWW333ఙఙ33M3Wవ3వ3ఙఙ33ఙ3వ3వవుXD3ఙఙMుుఙ34ుశ4-్WW3్y్ఙఔఙఙలఙఙMM3ఙMవఙఙఙ3nn3ఙ3ుMnnWnు3WWWWWW3ఃఃWWఙWWW్nః్వWWWWWWWWవఙXMXXవవవ3వ33333b33అః3ఃః333333ఞWఞఙఃXXXkవ3ఃఃఃnః33Wఙఙ3ఙ33WWWmఙyఅ33అ3333ఙ33జబWXWyఅఅఅఅఅmఙMఙఃఙఃఙఅఅఅఙఃఃఙఙఙఙఙఙఙWఙWఙఅWఙఞ3ఙఙఙఙఙఙ3ఙఙఙఙఙఙఙఙఙఙఙఙఙఙmఙఙఙWWఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙ3ఙ3ఙ3ఙఙఙ3ఙఙఙ33ఙ3టఙఅఙఅఅఅఅఅఅఅఅఃఃఅఃఙ3ఙఙఙఙఙఙఙఙWఙఙఙ,ఙఙఙఙఙఙఙఙఙఙ,ఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఃఙఙఙఙఙ3ఙఙఙఙ3ఙఅ3అ33ఙ333ఙ3333అఙఙదఙఙఙఙఅఙఅదఅవnఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙదఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙ8ఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙm్ఙ్ఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙ్ఙఙఙఙఙఙఙఙఙఙఙఙఖఙఖఙఙ\n",
      "Evaluation translation (should we go to the mall?) : ('దుుుుుుుుుుుాుుుుుు    ుుుుుుుుుుుుుుుుుుుుుుుుుుుుుుుుు    ుుుుుుుుుు   ుుు            ుుుుుుుుుుుుుిి ుుుుుుుుుుుుుు ుుు  ఙఙుుుుు  ఙఙఙ   ుుుుుుుుుుుుుుుుుుుుుుుుుుుుుుు   ుుుుుుుుు   ుుు MMMMుుు    ిఅ    అఅఅుుుుుు ుుుుుుుుుుుుుుుు   ుుుుుుుుుుుుుుుుుఅుుుుుుుుుుుుఅఅఅఅఙఙఙఙఙఙఙఙఙఙఅఅఅఃఃఙఙఙఙఙఙఙఙఙఙుుుఅఙఙఙ   మమఙఙఙఙఙఙఙఙఙఙుఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఅఅఅఅఅఅఅఅఅఅఅఅఅ  అఅఅఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙ ుుుుుఙఙఙ   అ ు              ఙఙఙఙఙఙఙఙఙఙఙఙఙుుుఙఙఙఙఙఙఙఙఙఙుుుఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙ    ఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙు్్్ఙఙఙఙఙ ఙఙఙఙ    ఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఙఖఙఙఙ',)\n",
      "-------------------------------------------\n",
      "Iteration 100 : 3.2106103897094727\n",
      "English: i'll stay a few more days.\n",
      "Kannada Translation: నేను మరికొన్ని రోజులు ఉంటాను.\n",
      "Kannada Prediction: టనము ్ నను    న్  ంంాున ా\n",
      "Evaluation translation (should we go to the mall?) : ('టామ   నా      ా   నుానుు.<END>',)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[299], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m valid_indicies \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(labels\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m kannada_to_index[PADDING_TOKEN], \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m valid_indicies\u001b[39m.\u001b[39msum()\n\u001b[0;32m---> 30\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     31\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[39m#train_losses.append(loss.item())\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, kn_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, kn_batch)\n",
    "        optim.zero_grad()\n",
    "        kn_predictions = transformer(eng_batch,\n",
    "                                     kn_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == kannada_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"Kannada Translation: {kn_batch[0]}\")\n",
    "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for idx in kn_sentence_predicted:\n",
    "              if idx == kannada_to_index[END_TOKEN]:\n",
    "                break\n",
    "              predicted_sentence += index_to_kannada[idx.item()]\n",
    "            print(f\"Kannada Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            kn_sentence = (\"\",)\n",
    "            eng_sentence = (\"should we go to the mall?\",)\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
    "                predictions = transformer(eng_sentence,\n",
    "                                          kn_sentence,\n",
    "                                          encoder_self_attention_mask.to(device), \n",
    "                                          decoder_self_attention_mask.to(device), \n",
    "                                          decoder_cross_attention_mask.to(device),\n",
    "                                          enc_start_token=False,\n",
    "                                          enc_end_token=False,\n",
    "                                          dec_start_token=True,\n",
    "                                          dec_end_token=False)\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_kannada[next_token_index]\n",
    "                kn_sentence = (kn_sentence[0] + next_token, )\n",
    "                if next_token == END_TOKEN:\n",
    "                  break\n",
    "            \n",
    "            print(f\"Evaluation translation (should we go to the mall?) : {kn_sentence}\")\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
